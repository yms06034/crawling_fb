{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "09fd5a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import pyperclip\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2834042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selenium_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--proxy-server=socks5://127.0.0.1:9150\")\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    options.add_argument('disable-gpu')\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('no-sandox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('incognito')\n",
    "    \n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    browser = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    return browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1869f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_to_bottom(browser):\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        time.sleep(1.5)\n",
    "\n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fdb52313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(browser, i_keyword, i_city = None):\n",
    "    try:\n",
    "        #open browser\n",
    "        browser.get(\"https://www.facebook.com/\")\n",
    "#         time.sleep(2)\n",
    "        \n",
    "        #log info, search keyword\n",
    "        USER = \"shm8485@gmail.com\"\n",
    "        PWD = \"sohee8485\"\n",
    "        KEYWORD = i_keyword\n",
    "        CITY = i_city\n",
    "        \n",
    "        #login\n",
    "        elem_id = browser.find_element(\"id\", \"email\")\n",
    "        pyperclip.copy(USER)\n",
    "        elem_id.send_keys(Keys.CONTROL, \"v\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        elem_pw = browser.find_element(\"id\", \"pass\")\n",
    "        pyperclip.copy(PWD)\n",
    "        elem_pw.send_keys(Keys.CONTROL, \"v\")\n",
    "        elem_pw.send_keys(\"\\n\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        #search\n",
    "        browser.get(f\"https://www.facebook.com/search/people/?q={KEYWORD}\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            elem_block = browser.find_element(\"xpath\", \"/html/body/div[3]/div[1]/div/div[2]/div/div/div/div/div/div/div[1]/div/div[2]/div\")\n",
    "            elem_block.click()\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            elem_block = browser.find_element('xpath', '/html/body/div[5]/div[1]/div/div[2]/div/div/div/div/div/div/div[1]/div/div[2]/div')\n",
    "            elem_block.click()\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #city\n",
    "        if CITY:\n",
    "            elem_city = browser.find_element(\"xpath\", \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div/div/div/div/div\")\n",
    "            elem_city.click()\n",
    "            elem_city = browser.find_element(\"xpath\", '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div/div/div/div/div/input')\n",
    "            time.sleep(1)\n",
    "            pyperclip.copy(CITY)\n",
    "            elem_city.send_keys(Keys.CONTROL, \"v\")\n",
    "            time.sleep(1)         \n",
    "            elem_city = browser.find_element('xpath', '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[2]/div/div/div[1]/div[1]/div/ul/li[1]/div/div[1]/div/div/div/div/div[2]/div/span/span')\n",
    "            elem_city.click()\n",
    "            time.sleep(1)      \n",
    "        \n",
    "    except:\n",
    "        browser.save_screenshot(\"screenshot_.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3c09daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(browser):\n",
    "    soup_profile = bs(browser.page_source, \"html.parser\")\n",
    "    top_elements = soup_profile.find_all(class_=\"x1yztbdb\")\n",
    "    final_href = []\n",
    "\n",
    "    for i in top_elements:\n",
    "        final_href.append(i.find(\"a\").attrs['href'])\n",
    "    \n",
    "    final_list = []\n",
    "    url_id = 'php?id='\n",
    "\n",
    "    for i in final_href:\n",
    "        if url_id in i:\n",
    "            href = i[:len(i)-11]+'&sk='\n",
    "        else:\n",
    "            href = i[:len(i)-11]+'/'\n",
    "        final_list.append(href)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "02db6934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_csv(f_name, name, contact, city):\n",
    "        df = pd.DataFrame({\"이름\":name,\n",
    "                           \"연락처\":contact,\n",
    "                           \"지역\":city})\n",
    "        df.to_csv(f\"{f_name}.csv\", encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2539f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawling(f_name, keyword, city= None):\n",
    "    browser = selenium_driver()\n",
    "    search(browser, keyword+'\\n', city)\n",
    "    \n",
    "    #scroll to bottom\n",
    "    top_to_bottom(browser)\n",
    "        \n",
    "    #scrap the profiles' link\n",
    "    final_list = get_links(browser)\n",
    "    name, contact, city = [], [], []\n",
    "    \n",
    "    for i in final_list:\n",
    "        try:\n",
    "            browser.get(i+\"about_contact_and_basic_info\")\n",
    "            time.sleep(1)\n",
    "            soup_info = bs(browser.page_source, \"html.parser\")\n",
    "            soup_name = soup_info.find(class_=\"x78zum5 x15sbx0n x5oxk1f x1jxijyj xym1h4x xuy2c7u x1ltux0g xc9uqle\")\n",
    "            name.append(soup_name.find(\"h1\").text)\n",
    "            soup_info_contact = soup_info.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "            contact.append(soup_info_contact.text)\n",
    "            browser.get(i+\"about_places\")\n",
    "            time.sleep(1)\n",
    "            soup_info = bs(browser.page_source, \"html.parser\")\n",
    "            soup_info_ct = soup_info.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "            city.append(soup_info_ct.text)\n",
    "        except:\n",
    "            l_name = len(name)\n",
    "            l_cont = len(contact)\n",
    "            l_city = len(city)\n",
    "            if l_name > l_cont:\n",
    "                contact.append('empty')\n",
    "                print(1)\n",
    "                try:\n",
    "                    browser.get(i+\"about_places\")\n",
    "                    time.sleep(1)\n",
    "                    soup_info = bs(browser.page_source, \"html.parser\")\n",
    "                    soup_info_ct = soup_info.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "                    city.append(soup_info_ct.text)\n",
    "                except:\n",
    "                    city.append('')\n",
    "            else:\n",
    "                city.append('')\n",
    "                \n",
    "    print_csv(f_name, name, contact, city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c4522270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(f_name, keyword, city=None):\n",
    "    start = time.time()\n",
    "    #crawling(file_name, keyword, city)\n",
    "    crawling(f_name, keyword, city)\n",
    "    print(\"소요 시간: \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9cb7cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소요 시간:  944.2355122566223\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main('test_tracvel''여행')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b8e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
