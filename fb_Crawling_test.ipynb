{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "934e07a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import time\n",
    "import pyperclip\n",
    "\n",
    "def selenium_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--proxy-server=socks5://127.0.0.1:9150\")\n",
    "    options.add_argument('window-size=1920x1080')\n",
    "    options.add_argument('disable-gpu')\n",
    "    options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('no-sandox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('incognito')\n",
    "    \n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    browser = webdriver.Chrome(service=service, options=options)\n",
    "    return browser\n",
    "                               \n",
    "if __name__ == \"__main__\":\n",
    "    browser = selenium_driver()\n",
    "    try:\n",
    "        #open browser\n",
    "        browser.get(\"https://www.facebook.com/\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        #log info, search keyword\n",
    "        USER = \"shm8485@gmail.com\"\n",
    "        PWD = \"sohee8485\"\n",
    "        KEYWORD = \"여행\\n\"\n",
    "        CITY = 'ansan '\n",
    "        \n",
    "        #login\n",
    "        elem_id = browser.find_element(\"id\", \"email\")\n",
    "        pyperclip.copy(USER)\n",
    "        elem_id.send_keys(Keys.CONTROL, \"v\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        elem_pw = browser.find_element(\"id\", \"pass\")\n",
    "        pyperclip.copy(PWD)\n",
    "        elem_pw.send_keys(Keys.CONTROL, \"v\")\n",
    "        elem_pw.send_keys(\"\\n\")\n",
    "#         browser.find_element(\"xpath\",\"/html/body/div[1]/div[1]/div[1]/div/div/div/div[2]/div/div[1]/form/div[2]/button\").click()\n",
    "        time.sleep(3)\n",
    "\n",
    "            #search\n",
    "        browser.get(f\"https://www.facebook.com/search/people/?q={KEYWORD}\")\n",
    "#         elem_search = browser.find_element(\"xpath\", \"/html/body/div[1]/div/div[1]/div/div[2]/div[3]/div/div/div/div/div/label/input\")\n",
    "#         time.sleep(2)\n",
    "#         pyperclip.copy(KEYWORD)\n",
    "#         elem_search.send_keys(Keys.CONTROL, \"v\")\n",
    "#         elem_search.send_keys(\"\\n\")\n",
    "    #     elem.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        try:\n",
    "            elem_block = browser.find_element(\"xpath\", \"/html/body/div[3]/div[1]/div/div[2]/div/div/div/div/div/div/div[3]/div/div/div/div/div/div/div/div[1]\")\n",
    "#             elem_block = browser.find_element(\"xpath\", \"/html/body/div[5]/div[1]/div/div[2]/div/div/div/div/div/div/div[3]/div/div/div/div/div/div/div\")\n",
    "            elem_block.click()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        #city\n",
    "        if CITY:\n",
    "            elem_city = browser.find_element(\"xpath\", \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div/div/div/div/div\")\n",
    "            elem_city.click()\n",
    "            elem_city = browser.find_element(\"xpath\", '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div/div/div/div/div/input')\n",
    "            time.sleep(1)\n",
    "            pyperclip.copy(CITY)\n",
    "            elem_city.send_keys(Keys.CONTROL, \"v\")\n",
    "            time.sleep(1)         \n",
    "            elem_city = browser.find_element('xpath', '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[2]/div/div/div[1]/div[1]/div/ul/li[1]/div/div[1]/div/div/div/div/div[2]/div/span/span')\n",
    "            elem_city.click()\n",
    "            time.sleep(1)         \n",
    "        \n",
    "        \n",
    "    except:\n",
    "        browser.save_screenshot(\"screenshot_.png\")\n",
    "    #     browser.close()\n",
    "    \n",
    "    \n",
    "    #scroll to bottom\n",
    "#     last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "#     while True:\n",
    "#         print(1)\n",
    "#         browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#         time.sleep(1)\n",
    "#         new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "#         if new_height == last_height:\n",
    "#             print(2)\n",
    "#             break\n",
    "#         last_height = new_height\n",
    "#     print(3)\n",
    "        \n",
    "#     #scrap the profiles' link\n",
    "#     soup_profile = bs(browser.page_source, \"html.parser\")\n",
    "#     top_elements = soup_profile.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305fa125",
   "metadata": {},
   "outputs": [],
   "source": [
    "        #city\n",
    "        if CITY:\n",
    "            elem_city = browser.find_element(\"xpath\", \"/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div/div/div/div/div\")\n",
    "            elem_city.click()\n",
    "            elem_city = browser.find_element(\"xpath\", '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[1]/div[1]/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]/div/div[3]/div[2]/div[2]/div/div/div/div/div/div/input')\n",
    "            time.sleep(1)\n",
    "            pyperclip.copy(CITY)\n",
    "            elem_city.send_keys(Keys.CONTROL, \"v\")\n",
    "            elem_city = browser.find_element('xpath', '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div/div[2]/div/div/div[1]/div[1]/div/ul/li[1]/div/div[1]/div/div/div/div/div[2]/div/span/span')\n",
    "            elem_city.click()\n",
    "            time.sleep(1)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f62282ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scroll to bottom\n",
    "last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    time.sleep(1.5)\n",
    "\n",
    "    new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e267e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #scrap the profiles' link\n",
    "    soup_profile = bs(browser.page_source, \"html.parser\")\n",
    "    top_elements = soup_profile.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7502c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_href = []\n",
    "\n",
    "for i in top_elements:\n",
    "    href = i.attrs['href']\n",
    "    final_href.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ab9e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.facebook.com/profile.php?id=\"\n",
    "lists = []\n",
    "\n",
    "for i in final_href:\n",
    "    if url in i:\n",
    "        a_lists = i.split(\"&\")\n",
    "        lists.append(a_lists)\n",
    "final_list = [i for i in lists if len(i) <= 1]\n",
    "print(len(final_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "392eb04b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m soup_info \u001b[38;5;241m=\u001b[39m bs(browser\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m soup_info_ctr \u001b[38;5;241m=\u001b[39m soup_info\u001b[38;5;241m.\u001b[39mfind(class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxyamay9 xqmdsaz x1gan7if x1swvt13\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m country\u001b[38;5;241m.\u001b[39mappend(\u001b[43msoup_info_ctr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "name, contact, city = [], [], []\n",
    "final_list = final_list[1:]\n",
    "for i in final_list:\n",
    "    browser.get(i[0]+\"&sk=about_contact_and_basic_info\")\n",
    "    time.sleep(1)\n",
    "    soup_info = bs(browser.page_source, \"html.parser\")\n",
    "    soup_name = soup_info.find(class_=\"x78zum5 x15sbx0n x5oxk1f x1jxijyj xym1h4x xuy2c7u x1ltux0g xc9uqle\")\n",
    "    name.append(soup_name.find(\"h1\").text)\n",
    "    soup_info_contact = soup_info.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "    contact.append(soup_info_contact.text)\n",
    "    browser.get(i[0]+\"&sk=about_places\")\n",
    "    time.sleep(1)\n",
    "    soup_info = bs(browser.page_source, \"html.parser\")\n",
    "    soup_info_ct = soup_info.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "    country.append(soup_info_ct.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32d9b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"이름\":name,\n",
    "                   \"연락처\":contact,\n",
    "                   \"지역\":country})\n",
    "df.to_csv(\"output_pd.csv\", encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8ff5d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "29\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(name))\n",
    "print(len(contact))\n",
    "print(len(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d579aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "92    False\n",
       "93    False\n",
       "94    False\n",
       "95    False\n",
       "96    False\n",
       "Name: 연락처, Length: 97, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('test_travel.csv', sep=',')\n",
    "# print(data['연락처'].str.contains('+82'))\n",
    "data['연락처]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59da43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "country.append(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49997410",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua.random\n",
    "\n",
    "name, contact, country = [], [], []\n",
    "final_list = final_list[1:5]\n",
    "for i in final_list:\n",
    "    browser.get(i[0]+\"&sk=about_contact_and_basic_info\")\n",
    "    time.sleep(1)\n",
    "    soup2 = bs(browser.page_source, \"html.parser\")\n",
    "    soup_name = soup2\n",
    "    soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "    name.append(soup2.find(\"h1\").text)\n",
    "    contact.append(soup2.text)\n",
    "    browser.get(i[0]+\"&sk=about_places\")\n",
    "    time.sleep(1)\n",
    "    soup2 = bs(browser.page_source, \"html.parser\")\n",
    "    soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "    country.append(soup2.text)\n",
    "    ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(final_list[1][0]+\"&sk=about_places\")\n",
    "soup2 = bs(browser.page_source, \"html.parser\")\n",
    "print(final_list[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df28fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(final_list[2][0]+\"&sk=about_places\")\n",
    "soup2 = bs(browser.page_source, \"html.parser\")\n",
    "print(soup2.find(\"h1\").text)\n",
    "soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "information = soup2.text\n",
    "print(information)\n",
    "\n",
    "browser.get(final_list[2][0]+\"&sk=about_contact_and_basic_info\")\n",
    "soup2 = bs(browser.page_source, \"html.parser\")\n",
    "soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "information = soup2.text\n",
    "print(information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(final_list[1][0]+\"&sk=about_places\")\n",
    "soup2 = bs(browser.page_source, \"html.parser\")\n",
    "print(soup2.find(\"h1\").text)\n",
    "soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "information = soup2.text\n",
    "print(information)\n",
    "\n",
    "browser.get(final_list[1][0]+\"&sk=about_contact_and_basic_info\")\n",
    "soup2 = bs(browser.page_source, \"html.parser\")\n",
    "soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "information = soup2.text\n",
    "print(information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(browsers=['chrome'])\n",
    "ua.random\n",
    "\n",
    "for i in final_list:\n",
    "    browser.get(i[0]+\"&sk=about_places\")\n",
    "    time.sleep(0.5)\n",
    "    soup2 = bs(browser.page_source, \"html.parser\")\n",
    "    soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "    information = soup2.text\n",
    "    print(information)\n",
    "    ua.random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d7129",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(final_list[0][0]+\"&sk=about_places\")\n",
    "soup2 = bs(browser.page_source, \"html.parser\")\n",
    "print(soup2.find(\"h1\").text)\n",
    "soup2 = soup2.find(class_=\"xyamay9 xqmdsaz x1gan7if x1swvt13\")\n",
    "information = soup2.text\n",
    "print(information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba29363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
